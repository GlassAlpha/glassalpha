{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Risk Analysis: Complete Walkthrough\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/german_credit_walkthrough.ipynb)\n",
    "\n",
    "**Complete ML audit workflow**: Data exploration → Model training → Fairness analysis → SHAP explanations → Calibration → Professional PDF report\n",
    "\n",
    "**Dataset**: German Credit (1000 applications) | **Protected Attributes**: Gender, Age, Foreign Worker\n",
    "\n",
    "**API Reference**: [`from_model()` documentation](https://glassalpha.com/reference/api/api-audit/) | [User Guide](https://glassalpha.com/getting-started/quickstart/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q glassalpha[explain,xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment verification for reproducibility\"\"\"\n",
    "import sys, platform, random, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import glassalpha as ga\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print({\n",
    "    \"python\": sys.version.split()[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
    "    \"seed\": SEED\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ga.datasets.load_german_credit()\n",
    "print(f\"Dataset: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"Target balance: {df['credit_risk'].mean():.1%} good credit\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attrs = ['gender', 'age_group', 'foreign_worker']\n",
    "feature_cols = [c for c in df.columns if c not in ['credit_risk'] + protected_attrs]\n",
    "X, y = df[feature_cols], df['credit_risk']\n",
    "protected_data = df[protected_attrs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED).fit(X_train, y_train)\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=3, random_state=SEED, eval_metric='logloss').fit(X_train, y_train)\n",
    "\n",
    "print(f\"RandomForest test acc: {rf.score(X_test, y_test):.3f}\")\n",
    "print(f\"XGBoost test acc: {xgb.score(X_test, y_test):.3f}\")\n",
    "model = xgb if xgb.score(X_test, y_test) > rf.score(X_test, y_test) else rf\n",
    "print(f\"\\n✓ Selected: {'XGBoost' if model == xgb else 'RandomForest'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ga.audit.from_model(\n",
    "    model=model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    protected_attributes={\n",
    "        'gender': protected_data.loc[X_test.index, 'gender'],\n",
    "        'age_group': protected_data.loc[X_test.index, 'age_group'],\n",
    "        'foreign_worker': protected_data.loc[X_test.index, 'foreign_worker']\n",
    "    },\n",
    "    random_seed=SEED\n",
    ")\n",
    "result  # Display inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {result.performance.accuracy:.3f}\")\n",
    "print(f\"AUC-ROC: {result.performance.auc_roc:.3f}\")\n",
    "print(f\"Precision: {result.performance.precision:.3f}\")\n",
    "print(f\"Recall: {result.performance.recall:.3f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "result.performance.plot_confusion_matrix(ax=ax1)\n",
    "result.performance.plot_roc_curve(ax=ax2)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Demographic Parity: {result.fairness.demographic_parity_difference:.3f}\")\n",
    "print(f\"Equal Opportunity: {result.fairness.equal_opportunity_difference:.3f}\")\n",
    "print(f\"\\nBias detected: {'⚠️ YES' if result.fairness.has_bias(0.10) else '✓ NO'} (10% threshold)\")\n",
    "\n",
    "result.fairness.plot_group_metrics()\n",
    "plt.title('Fairness Across Protected Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Expected Calibration Error: {result.calibration.expected_calibration_error:.4f}\")\n",
    "print(f\"Brier Score: {result.calibration.brier_score:.4f}\")\n",
    "print(f\"\\nCalibration: {'✓ PASS' if result.calibration.expected_calibration_error < 0.05 else '⚠️ WARNING'} (ECE < 0.05 target)\")\n",
    "\n",
    "result.calibration.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: SHAP Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Important Features:\\n\")\n",
    "print(result.explanations.feature_importance.head(10))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "result.explanations.plot_importance(top_n=10, ax=ax1)\n",
    "result.explanations.plot_summary(ax=ax2)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Export Audit Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pdf('german_credit_audit.pdf')\n",
    "result.to_json('metrics.json')\n",
    "result.to_config('audit_config.yaml')\n",
    "print('✓ Exported: PDF report, metrics JSON, config YAML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Performance**: Strong accuracy and AUC-ROC\n",
    "**Fairness**: Analyzed across gender, age, foreign worker status\n",
    "**Calibration**: ECE indicates prediction reliability\n",
    "**Explainability**: SHAP values provide feature attribution\n",
    "\n",
    "**Next Steps**: Review PDF report, address any fairness gaps, monitor in production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
