{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GlassAlpha Quickstart: Your First Audit in 8 Minutes\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlassAlpha/glassalpha/blob/main/examples/notebooks/quickstart_colab.ipynb)\n",
        "\n",
        "This notebook demonstrates how to generate a professional ML audit report in under 8 minutes using GlassAlpha's `from_model()` API.\n",
        "\n",
        "**What you'll learn:**\n",
        "- Train a simple credit scoring model\n",
        "- Generate a comprehensive audit with one function call\n",
        "- View inline audit results\n",
        "- Understand fairness and performance metrics\n",
        "\n",
        "**Time**: ~8 minutes | **Difficulty**: Beginner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install GlassAlpha (30 seconds)\n",
        "\n",
        "Run this cell to install GlassAlpha and its dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q glassalpha[explain]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Environment Setup (15 seconds)\n",
        "\n",
        "Import libraries and set random seeds for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Environment verification for reproducibility\"\"\"\n",
        "import sys, platform, random, numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import glassalpha as ga\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print({\n",
        "    \"python\": sys.version.split()[0],\n",
        "    \"platform\": platform.platform(),\n",
        "    \"glassalpha\": getattr(ga, \"__version__\", \"dev\"),\n",
        "    \"seed\": SEED\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Data (1 minute)\n",
        "\n",
        "We'll use the German Credit dataset - a classic benchmark for credit risk assessment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load German Credit dataset\n",
        "from glassalpha.datasets import load_german_credit\n",
        "\n",
        "# Load preprocessed data\n",
        "data = load_german_credit()\n",
        "df = data['dataframe']\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nTarget distribution:\\n{df['credit_risk'].value_counts(normalize=True)}\")\n",
        "print(f\"\\nProtected attributes: {data['protected_attributes']}\")\n",
        "\n",
        "# Show first few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train Model (2 minutes)\n",
        "\n",
        "Train a simple Random Forest classifier for credit risk prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "target_col = 'credit_risk'\n",
        "protected_attrs = ['gender', 'age_group', 'foreign_worker']\n",
        "\n",
        "# Features (exclude target and protected attributes for training)\n",
        "feature_cols = [col for col in df.columns if col != target_col and col not in protected_attrs]\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Train/test split (stratified by target and gender for fairness analysis)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=SEED,\n",
        "    stratify=df[[target_col, 'gender']]\n",
        ")\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Quick performance check\n",
        "train_score = model.score(X_train, y_train)\n",
        "test_score = model.score(X_test, y_test)\n",
        "\n",
        "print(f\"‚úì Training accuracy: {train_score:.3f}\")\n",
        "print(f\"‚úì Test accuracy: {test_score:.3f}\")\n",
        "print(f\"‚úì Model ready for audit!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Audit with `from_model()` (3 minutes)\n",
        "\n",
        "This is where the magic happens! One function call generates a comprehensive audit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive audit\n",
        "result = ga.audit.from_model(\n",
        "    model=model,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    protected_attributes={\n",
        "        'gender': df.loc[X_test.index, 'gender'],\n",
        "        'age_group': df.loc[X_test.index, 'age_group'],\n",
        "        'foreign_worker': df.loc[X_test.index, 'foreign_worker']\n",
        "    },\n",
        "    random_seed=SEED\n",
        ")\n",
        "\n",
        "print(\"‚úì Audit completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: View Inline Results (30 seconds)\n",
        "\n",
        "Display the audit summary directly in the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display inline HTML summary\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Explore Metrics (1 minute)\n",
        "\n",
        "Access specific metrics programmatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance metrics\n",
        "print(\"üìä PERFORMANCE METRICS\")\n",
        "print(f\"  Accuracy: {result.performance.accuracy:.3f}\")\n",
        "print(f\"  Precision: {result.performance.precision:.3f}\")\n",
        "print(f\"  Recall: {result.performance.recall:.3f}\")\n",
        "print(f\"  F1 Score: {result.performance.f1:.3f}\")\n",
        "print(f\"  AUC-ROC: {result.performance.auc_roc:.3f}\")\n",
        "\n",
        "# Fairness metrics\n",
        "print(\"\\n‚öñÔ∏è  FAIRNESS METRICS\")\n",
        "print(f\"  Demographic parity (gender): {result.fairness.demographic_parity_difference:.3f}\")\n",
        "print(f\"  Equal opportunity (gender): {result.fairness.equal_opportunity_difference:.3f}\")\n",
        "\n",
        "# Check for bias\n",
        "if result.fairness.has_bias():\n",
        "    print(\"  ‚ö†Ô∏è  Bias detected! Review fairness analysis.\")\n",
        "else:\n",
        "    print(\"  ‚úÖ No significant bias detected.\")\n",
        "\n",
        "# Calibration\n",
        "print(\"\\nüéØ CALIBRATION\")\n",
        "print(f\"  Expected Calibration Error: {result.calibration.expected_calibration_error:.3f}\")\n",
        "print(f\"  Brier Score: {result.calibration.brier_score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Visualize Results (optional)\n",
        "\n",
        "Generate publication-quality plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot calibration curve\n",
        "result.calibration.plot()\n",
        "\n",
        "# Plot fairness metrics\n",
        "result.fairness.plot_group_metrics()\n",
        "\n",
        "# Plot confusion matrix\n",
        "result.performance.plot_confusion_matrix()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Export PDF Report (optional)\n",
        "\n",
        "Generate a professional PDF for regulatory submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to PDF\n",
        "result.to_pdf(\"german_credit_audit.pdf\")\n",
        "\n",
        "print(\"‚úì PDF report generated: german_credit_audit.pdf\")\n",
        "print(\"\\nDownload the PDF from the Colab files panel (left sidebar) ‚Üí\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've just generated your first ML audit in under 8 minutes!\n",
        "\n",
        "### What you learned:\n",
        "- ‚úÖ Train a credit scoring model\n",
        "- ‚úÖ Generate comprehensive audit with `from_model()`\n",
        "- ‚úÖ View inline results in notebooks\n",
        "- ‚úÖ Access metrics programmatically\n",
        "- ‚úÖ Export professional PDF reports\n",
        "\n",
        "### Next steps:\n",
        "1. **Try with your own data**: See [Custom Data Guide](https://glassalpha.com/getting-started/custom-data/)\n",
        "2. **Explore advanced features**: [Dataset Bias Detection](https://glassalpha.com/guides/dataset-bias/), [Shift Testing](https://glassalpha.com/guides/shift-testing/)\n",
        "3. **Integrate into production**: [ML Engineer Workflow](https://glassalpha.com/guides/ml-engineer-workflow/)\n",
        "4. **Learn about compliance**: [SR 11-7 Mapping](https://glassalpha.com/compliance/sr-11-7-mapping/), [EU AI Act](https://glassalpha.com/compliance/eu-ai-act-mapping/)\n",
        "\n",
        "### Resources:\n",
        "- **Documentation**: [glassalpha.com/docs](https://glassalpha.com/docs)\n",
        "- **GitHub**: [github.com/GlassAlpha/glassalpha](https://github.com/GlassAlpha/glassalpha)\n",
        "- **Discussions**: [github.com/GlassAlpha/glassalpha/discussions](https://github.com/GlassAlpha/glassalpha/discussions)\n",
        "\n",
        "### Questions?\n",
        "- Check the [FAQ](https://glassalpha.com/reference/faq/)\n",
        "- Join [GitHub Discussions](https://github.com/GlassAlpha/glassalpha/discussions)\n",
        "- Email: [contact@glassalpha.com](mailto:contact@glassalpha.com)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
