# GlassAlpha Example: German Credit Risk Assessment
# Usage: glassalpha audit --config german_credit.yaml --output german_credit_audit.html
# Built-in dataset: german_credit (automatically fetched)
#
# This is a RUNNABLE EXAMPLE that works out-of-the-box.
# For customization guidance: https://glassalpha.com/getting-started/custom-data/

# German Credit Dataset Audit Configuration
# This configuration demonstrates a complete ML audit pipeline for credit risk assessment
# using the German Credit dataset with fairness and bias analysis.

# =============================================================================
# AUDIT PROFILE AND BASIC SETTINGS
# =============================================================================

# Audit profile determines which components and validations are applied
audit_profile: "tabular_compliance"

# Strict mode enforces regulatory compliance requirements
# - Explicit random seeds (no defaults)
# - Locked data schema (no inference)
# - Full manifest generation
# - Deterministic plugin selection
# Note: Set to true for production/regulatory environments
strict_mode: false

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

model:
  # Model type - triggers XGBoostWrapper from registry
  type: "xgboost"

  # Path to pre-trained model (optional - will train new model if not found)
  # path: "models/german_credit_xgboost.pkl"

  # Additional model parameters (optional)
  params:
    max_depth: 6
    learning_rate: 0.1
    n_estimators: 100
    objective: "binary:logistic"
    eval_metric: "logloss"

# =============================================================================
# DATA CONFIGURATION
# =============================================================================

data:
  # Use built-in German Credit dataset
  # FIXME: Audit pipeline doesn't split data - uses all samples for both training and testing
  # This causes 99% accuracy (data leakage). Need to add train/test split to audit pipeline.
  dataset: "german_credit"

  # Target and feature definitions
  target_column: "credit_risk"

  # Protected attributes for fairness analysis
  # These are sensitive demographic characteristics that should not lead to discrimination
  protected_attributes:
    - "personal_status_sex" # Personal status and gender combined
    - "age_years" # Age in years
    - "foreign_worker" # Nationality/residency status

  # Intersectional fairness analysis (E5.1)
  # Analyze bias at intersections of protected attributes
  # Format: "attr1*attr2" for two-way intersections
  intersections:
    # Example: Does the model treat young foreign workers differently than old citizens?
    - "age_years*foreign_worker"
    # Example: Does personal status interact with age to create bias?
    - "personal_status_sex*age_years"

# =============================================================================
# PREPROCESSING CONFIGURATION
# =============================================================================

# Preprocessing is handled automatically by the built-in German Credit dataset

# =============================================================================
# EXPLAINER CONFIGURATION
# =============================================================================

explainers:
  # Strategy for selecting explainers (deterministic for reproducibility)
  strategy: "first_compatible"

  # Priority order - first compatible explainer will be selected
  priority:
    - "treeshap" # TreeSHAP - exact SHAP values for tree models (preferred)
    - "kernelshap" # KernelSHAP - model-agnostic fallback
    - "noop" # No-op fallback (should not be reached)

  # Explainer-specific configuration
  config:
    treeshap:
      # Maximum samples for SHAP value computation
      max_samples: 1000
      # Check additivity property (TreeSHAP should always be additive)
      check_additivity: true

    kernelshap:
      # Number of samples for model-agnostic SHAP approximation
      n_samples: 500
      # Background dataset size for KernelSHAP
      background_size: 100

# =============================================================================
# METRICS CONFIGURATION
# =============================================================================

metrics:
  # Performance metrics for model evaluation
  performance:
    - "accuracy" # Overall classification accuracy
    - "precision" # Positive predictive value
    - "recall" # Sensitivity/true positive rate
    - "f1" # Harmonic mean of precision and recall
    - "auc_roc" # Area under ROC curve
    - "classification_report" # Comprehensive classification metrics

  # Fairness metrics for bias detection
  fairness:
    - "demographic_parity" # Statistical parity across demographic groups
    - "equal_opportunity" # Equal true positive rates across groups
    - "equalized_odds" # Equal TPR and FPR across groups
    - "predictive_parity" # Equal precision across demographic groups

  # Performance optimization: disable confidence intervals and enable performance mode for faster computation
  compute_confidence_intervals: false # Disable for 10x performance improvement
  n_bootstrap: 100 # Reduced from 1000
  performance_mode: true # Enable performance mode to reduce fairness metrics

  # Drift metrics for model stability (requires reference data)
  drift:
    - "population_stability_index" # PSI for distribution shift detection
    - "kl_divergence" # KL divergence between distributions
    - "kolmogorov_smirnov" # Two-sample test for distribution changes

# =============================================================================
# REPRODUCIBILITY CONFIGURATION
# =============================================================================

reproducibility:
  # Master random seed for all randomness sources
  random_seed: 42

  # Enforce deterministic behavior across all components
  deterministic: true

  # Capture complete execution environment
  capture_environment: true

# =============================================================================
# REPORT CONFIGURATION
# =============================================================================

report:
  # Template for report generation
  template: "standard_audit"

  # Output format (PDF is primary target)
  output_format: "html" # Use HTML for fast generation (change to "pdf" for regulatory submission)

  # Report sections to include
  include_sections:
    - "executive_summary" # High-level findings and risk assessment
    - "data_overview" # Dataset characteristics and quality
    - "model_performance" # Performance metrics and validation
    - "global_explanations" # Feature importance and model behavior
    - "local_explanations" # Individual prediction explanations
    - "fairness_analysis" # Bias detection and demographic analysis
    - "drift_detection" # Model stability and data shift analysis
    - "audit_manifest" # Complete reproducibility information
    - "regulatory_compliance" # Compliance checklist and recommendations

# =============================================================================
# RECOURSE CONFIGURATION (Advanced Feature)
# =============================================================================

recourse:
  # Enable recourse generation for individual predictions
  enabled: true

  # Features that cannot be changed (immutable constraints)
  immutable_features:
    - "age_years" # Age cannot be changed
    - "gender" # Gender is protected characteristic
    - "personal_status_sex" # Personal status is largely fixed
    - "foreign_worker" # Nationality/residency status

  # Directional constraints (features that can only improve)
  monotonic_constraints:
    credit_amount: "decrease_only" # Lower loan amount is safer
    duration_months: "decrease_only" # Shorter duration is safer
    savings_account: "increase_only" # More savings is always better
    employment_duration: "increase_only" # Longer employment is better
    existing_credits_count: "decrease_only" # Fewer existing credits is better
