"""Scikit-learn model wrappers for Glass Alpha audit pipeline.

This module provides wrappers for scikit-learn models, making them compatible
with the Glass Alpha audit interface. It includes LogisticRegression and
generic scikit-learn model wrappers.
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Any

import joblib
import numpy as np

# Conditional imports for sklearn
try:
    from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.linear_model import LogisticRegression

    SKLEARN_AVAILABLE = True
except ImportError:
    # Fallback when sklearn unavailable
    BaseEstimator = object
    ClassifierMixin = object
    LogisticRegression = None
    SKLEARN_AVAILABLE = False

from glassalpha.core.registry import ModelRegistry

if TYPE_CHECKING:
    from collections.abc import Sequence

logger = logging.getLogger(__name__)


class SklearnGenericWrapper:
    """Generic wrapper for scikit-learn models."""

    def __init__(self, model: Any, feature_names: Sequence[str] | None = None) -> None:  # noqa: ANN401
        """Initialize sklearn model wrapper.

        Args:
            model: Trained scikit-learn model
            feature_names: Optional feature names for interpretation

        """
            self.model = model
        self.feature_names = list(feature_names) if feature_names is not None else None
        self.capabilities = {
            "predict": hasattr(model, "predict"),
            "predict_proba": hasattr(model, "predict_proba"),
            "feature_importance": hasattr(model, "feature_importances_") or hasattr(model, "coef_"),
        }

    def predict(self, x: Any) -> Any:  # noqa: ANN401
        """Make predictions using the underlying model.

        Args:
            x: Input features for prediction

        Returns:
            Predictions from the underlying model

        """
        if not hasattr(self.model, "predict"):
            msg = "Underlying model has no predict"
            raise AttributeError(msg)
        return self.model.predict(x)

    def predict_proba(self, x: Any) -> Any:  # noqa: ANN401
        """Get prediction probabilities using the underlying model.

        Args:
            x: Input features for probability prediction

        Returns:
            Prediction probabilities from the underlying model

        """
        if not hasattr(self.model, "predict_proba"):
            msg = "Underlying model has no predict_proba"
            raise AttributeError(msg)
        return self.model.predict_proba(x)

    def feature_importance(self) -> dict[str, float]:
        """Get feature importance from the underlying model.

        Returns:
            Dictionary mapping feature names to importance values

        """
        if hasattr(self.model, "feature_importances_"):
            vals = np.asarray(self.model.feature_importances_)
        elif hasattr(self.model, "coef_"):
            vals = np.asarray(self.model.coef_)
            vals = np.mean(np.abs(vals), axis=0) if vals.ndim > 1 else np.abs(vals)
        else:
            msg = "Model exposes no feature importances"
            raise AttributeError(msg)
        names = self.feature_names or [f"f{i}" for i in range(len(vals))]
        return dict(zip(names, vals.tolist(), strict=False))

    def save(self, path: str) -> None:
        """Save model and feature names to disk.

        Args:
            path: Path to save the model

        """
        joblib.dump({"model": self.model, "feature_names": self.feature_names}, path)

    @classmethod
    def load(cls, path: str) -> SklearnGenericWrapper:
        """Load model from disk.

        Args:
            path: Path to the saved model

        Returns:
            New SklearnGenericWrapper instance with loaded model

        """
        data = joblib.load(path)
        return cls(model=data["model"], feature_names=data.get("feature_names"))

    # Some tests call instance.load(); keep a passthrough
    def load_instance(self, path: str) -> SklearnGenericWrapper:
        """Load model from path (instance method for compatibility).

        Args:
            path: Path to load the model from

        Returns:
            New SklearnGenericWrapper instance with loaded model

        """
        return self.__class__.load(path)

    def __repr__(self) -> str:
        """String representation of the wrapper.

        Returns:
            String representation showing wrapper class and model type

        """
        return f"{self.__class__.__name__}(model={type(self.model).__name__})"


class LogisticRegressionWrapper(SklearnGenericWrapper):
    """Stub wrapper for LogisticRegression (real implementation below)."""


# Only register if sklearn is available
if SKLEARN_AVAILABLE:

    @ModelRegistry.register("logistic_regression", priority=80)
    class LogisticRegressionWrapper(BaseEstimator, ClassifierMixin):
        """Wrapper for scikit-learn LogisticRegression with Glass Alpha compatibility."""

        # Required class attributes for ModelInterface
        capabilities = {
            "supports_shap": True,
            "supports_feature_importance": True,
            "supports_proba": True,
            "data_modality": "tabular",
            "feature_names": True,
        }
        version = "1.0.0"
        model_type = "logistic_regression"

        def __init__(self, model=None, feature_names=None, **kwargs) -> None:
            """Initialize LogisticRegression wrapper.

            Args:
                model: Pre-fitted LogisticRegression model or None to create new one
                feature_names: List of feature names
                **kwargs: Parameters passed to LogisticRegression constructor

            """
            if model is not None:
                # Use provided model
                self.model = model
                self.feature_names = list(feature_names) if feature_names else None
                self._is_fitted = hasattr(model, "coef_") and model.coef_ is not None
                # Set n_classes if model is fitted (tests expect this)
                if hasattr(model, "classes_") and model.classes_ is not None:
                    self.classes_ = model.classes_
                    self.n_classes = len(model.classes_)
                else:
                    self.n_classes = None
            elif kwargs:
                # Create new model with parameters
                self.model = LogisticRegression(**kwargs)
                self.feature_names = list(feature_names) if feature_names else None
                self._is_fitted = False
                self.n_classes = None
            else:
                # Tests expect model to be None when no arguments provided
                self.model = None
                self.feature_names = list(feature_names) if feature_names else None
                self._is_fitted = False
                self.n_classes = None

            logger.info("LogisticRegressionWrapper initialized")

        def fit(self, X, y, **kwargs):
            """Fit the logistic regression model."""
            # Create model if it doesn't exist
            if self.model is None:
                self.model = LogisticRegression(random_state=42, max_iter=1000)

            # Store feature names if X is DataFrame
            if hasattr(X, "columns") and self.feature_names is None:
                self.feature_names = list(X.columns)

            # Fit the model
            self.model.fit(X, y, **kwargs)
            self._is_fitted = True

            # Store classes for compatibility and set n_classes
            self.classes_ = self.model.classes_
            self.n_classes = len(self.classes_)

            return self

        def predict(self, X):
            """Make predictions."""
            if self.model is None:
                msg = "No model loaded"
                raise RuntimeError(msg)
            if not self._is_fitted:
                msg = "Model not fitted"
                raise RuntimeError(msg)

            # Validate and reorder features if needed
            X_processed = self._validate_and_reorder_features(X)
            predictions = self.model.predict(X_processed)

            # Ensure 1D numpy array output
            return np.array(predictions).flatten()

        def predict_proba(self, X):
            """Get prediction probabilities."""
            if not self._is_fitted:
                msg = "Model not fitted"
                raise RuntimeError(msg)

            # Validate and reorder features if needed
            X_processed = self._validate_and_reorder_features(X)
            return self.model.predict_proba(X_processed)

        def _validate_and_reorder_features(self, X):
            """Validate and reorder features to match training data."""
            # If no stored feature names, return as-is
            if self.feature_names is None:
                return X

            # If X has columns, ensure they match expected features
            if hasattr(X, "columns"):
                # Check for missing/extra features with clean error message (tests expect this format)
                provided_features = list(map(str, X.columns.tolist()))
                expected_features = list(map(str, self.feature_names))
                
                provided_set = set(provided_features)
                expected_set = set(expected_features)
                
                missing = sorted(expected_set - provided_set)
                extra = sorted(provided_set - expected_set)
                
                if missing or extra:
                    # Clean error message format that tests expect (not raw sklearn message)
                    raise ValueError(
                        "Feature names mismatch between fitted and provided data. "
                        f"Missing: {missing or '[]'}; Extra: {extra or '[]'}"
                    )

                # Reorder columns to match training order
                try:
                    return X[self.feature_names]
                except KeyError:
                    # Fallback to numpy array if column reordering fails
                    return X.values

            # For arrays, just return as-is (assume correct order)
            return X

        def get_params(self, deep=True):
            """Get model parameters."""
            return self.model.get_params(deep=deep)

        def set_params(self, **params):
            """Set model parameters."""
            return self.model.set_params(**params)

        @property
        def classes_(self):
            """Get fitted classes."""
            if hasattr(self.model, "classes_"):
                return self.model.classes_
            return None

        @classes_.setter
        def classes_(self, value) -> None:
            """Set classes (for compatibility)."""
            if hasattr(self.model, "classes_"):
                self.model.classes_ = value

        def get_feature_importance(self, importance_type="coef"):
            """Get feature importance from coefficients."""
            if not self._is_fitted:
                msg = "Model not fitted"
                raise RuntimeError(msg)

            if importance_type == "coef":
                # Use raw coefficients
                importance = np.abs(self.model.coef_[0])  # Take first class for binary
            else:
                msg = f"Unknown importance type: {importance_type}"
                raise ValueError(msg)

            # Create importance dict
            feature_names = self.feature_names or [f"feature_{i}" for i in range(len(importance))]
            return dict(zip(feature_names, importance.tolist(), strict=False))

        def get_model_info(self):
            """Get model information."""
            return {
                "status": "fitted" if self._is_fitted else "not_fitted",
                "n_features": len(self.feature_names) if self.feature_names else None,
                "n_classes": self.n_classes,  # Always include n_classes (tests expect this key)
                **self.get_params(),
            }

        def get_capabilities(self):
            """Get model capabilities."""
            return self.capabilities.copy()

        def get_model_type(self):
            """Get model type string."""
            return self.model_type

        def save(self, path: str) -> None:
            """Save model to file."""
            if self.model is None:
                # Tests expect this to raise when no model is loaded
                msg = "Cannot save LogisticRegressionWrapper: no model fitted/loaded"
                raise ValueError(msg)

            import joblib

            model_data = {
                "model": self.model,
                "feature_names": self.feature_names,
                "n_classes": self.n_classes,
                "_is_fitted": self._is_fitted,
            }
            joblib.dump(model_data, path)

        @classmethod
        def load(cls, path: str):
            """Load model from file."""
            import joblib

            model_data = joblib.load(path)
            wrapper = cls()
            wrapper.model = model_data["model"]
            wrapper.feature_names = model_data.get("feature_names")
            wrapper.n_classes = model_data.get("n_classes")
            wrapper._is_fitted = model_data.get("_is_fitted", False)
            
            # Restore classes_ attribute if model has it (needed for some tests)
            if wrapper.model is not None and hasattr(wrapper.model, "classes_"):
                wrapper.classes_ = wrapper.model.classes_
                
            return wrapper

    def __repr__(self) -> str:
            """String representation."""
            status = "fitted" if self._is_fitted else "not_fitted"
            n_classes = len(self.classes_) if hasattr(self, "classes_") and self.classes_ is not None else "unknown"
            return f"LogisticRegressionWrapper(status={status}, n_classes={n_classes}, version={self.version})"

@ModelRegistry.register("sklearn_generic", priority=70)
    class SklearnGenericWrapper(BaseEstimator):
        """Generic wrapper for any scikit-learn estimator."""

        # Required class attributes
    capabilities = {
            "supports_shap": True,
            "supports_feature_importance": True,
            "supports_proba": False,  # Will be updated based on model
        "data_modality": "tabular",
    }
    version = "1.0.0"
        model_type = "sklearn_generic"

        def __init__(self, model=None, feature_names=None, **kwargs) -> None:
        """Initialize generic sklearn wrapper.

        Args:
                model: Pre-fitted sklearn model
                feature_names: List of feature names
                **kwargs: If provided without model, raises error

            """
            if model is None and kwargs:
                msg = "SklearnGenericWrapper requires a fitted model when kwargs provided"
                raise ValueError(msg)

            self.model = model
            self.feature_names = list(feature_names) if feature_names else None

            # Update capabilities based on model
            if model:
                self.capabilities["supports_proba"] = hasattr(model, "predict_proba")

            logger.info("SklearnGenericWrapper initialized")

        def predict(self, X):
            """Make predictions."""
        if self.model is None:
                msg = "No model loaded"
                raise RuntimeError(msg)
            return self.model.predict(X)

        def predict_proba(self, X):
            """Get prediction probabilities if supported."""
        if self.model is None:
                msg = "No model loaded"
                raise RuntimeError(msg)
        if not hasattr(self.model, "predict_proba"):
                msg = "Model does not support predict_proba"
                raise AttributeError(msg)
            return self.model.predict_proba(X)

        def get_feature_importance(self, importance_type="auto"):
            """Get feature importance."""
        if self.model is None:
                msg = "No model loaded"
                raise RuntimeError(msg)

        if hasattr(self.model, "feature_importances_"):
                importance = self.model.feature_importances_
        elif hasattr(self.model, "coef_"):
            coef = self.model.coef_
                if coef.ndim > 1:
                    # Multi-class: take mean absolute coefficients
                    importance = np.mean(np.abs(coef), axis=0)
        else:
                    importance = np.abs(coef)
        else:
                # Fallback: uniform importance
                n_features = len(self.feature_names) if self.feature_names else 1
                importance = np.ones(n_features) / n_features

            feature_names = self.feature_names or [f"feature_{i}" for i in range(len(importance))]
            return dict(zip(feature_names, importance.tolist(), strict=False))

        def get_model_type(self):
            """Get model type."""
            return self.model_type

        def get_capabilities(self):
            """Get model capabilities."""
            return self.capabilities.copy()

        def get_model_info(self):
            """Get model information."""
            return {
                "model_type": self.model_type,
                "version": self.version,
                "has_model": self.model is not None,
            }

        def save(self, path: str) -> None:
            """Save model to file."""
            import joblib

            model_data = {
                "model": self.model,
                "feature_names": self.feature_names,
            }
            joblib.dump(model_data, path)

        @classmethod
        def load(cls, path: str):
            """Load model from file."""
            import joblib

            model_data = joblib.load(path)
            wrapper = cls()
            wrapper.model = model_data["model"]
            wrapper.feature_names = model_data.get("feature_names")
            return wrapper

    def __repr__(self) -> str:
            """String representation."""
        model_name = type(self.model).__name__ if self.model else "None"
            return f"SklearnGenericWrapper(model={model_name}, version={self.version})"

else:
    # Stub classes when sklearn unavailable
    class LogisticRegressionWrapper:
        """Stub class when scikit-learn is unavailable."""

        def __init__(self, *args, **kwargs) -> None:
            """Initialize stub - raises ImportError."""
            msg = "scikit-learn not available - install sklearn or fix CI environment"
            raise ImportError(msg)

    class SklearnGenericWrapper:
        """Stub class when scikit-learn is unavailable."""

        def __init__(self, *args, **kwargs) -> None:
            """Initialize stub - raises ImportError."""
            msg = "scikit-learn not available - install sklearn or fix CI environment"
            raise ImportError(msg)
